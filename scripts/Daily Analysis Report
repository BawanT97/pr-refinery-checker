import os
import re
import io
import json
import datetime as dt
import requests

# Optional parsers (install as needed):
# pip install pandas openpyxl pdfplumber pypdf
try:
    import pandas as pd
except Exception:
    pd = None

try:
    import pdfplumber
except Exception:
    pdfplumber = None

try:
    from pypdf import PdfReader
except Exception:
    PdfReader = None

# =========================
# CONFIG - BOX API (Client Credentials Grant - PERMANENT)
# =========================
# Box OAuth 2.0 Client Credentials (never expires)
BOX_CLIENT_ID = os.environ.get("BOX_CLIENT_ID", "0o3518woygv1tnj13ag85uf26ei2f0n7").strip()
BOX_CLIENT_SECRET = os.environ.get("BOX_CLIENT_SECRET", "AFcqfModQrmyY0hIzOS1BeaXS5DKzCdI").strip()

# Box Folder ID for "Daily Analysis Report" folder
BOX_FOLDER_ID = os.environ.get("BOX_FOLDER_ID", "360216207983").strip()

# File extensions to read
READ_EXTS = tuple(
    e.strip().lower()
    for e in os.environ.get("READ_EXTS", ".xlsx,.xls,.csv,.pdf").split(",")
    if e.strip()
)

# Optional keyword filter
KEYWORDS = tuple(
    k.strip().lower()
    for k in os.environ.get("READ_KEYWORDS", "").split(",")
    if k.strip()
)

# Per-file token cap (approx)
TOKENS_PER_FILE = int(os.environ.get("TOKENS_PER_FILE", "10000"))
CHARS_PER_TOKEN = float(os.environ.get("CHARS_PER_TOKEN", "4"))
MAX_CHARS_PER_FILE = int(TOKENS_PER_FILE * CHARS_PER_TOKEN)

# Hard byte cap
MAX_BYTES_PER_FILE = int(os.environ.get("MAX_BYTES_PER_FILE", str(50 * 1024 * 1024)))

DATE_RE = re.compile(r"^\d{2}-\d{2}-\d{4}$")

# Global access token cache
_access_token = None
_token_expires_at = None

# =========================
# BOX API HELPERS (Client Credentials Grant)
# =========================
def get_access_token():
    """Get access token using Client Credentials Grant (OAuth 2.0)"""
    global _access_token, _token_expires_at
    
    # Return cached token if still valid (with 5 min buffer)
    if _access_token and _token_expires_at:
        if dt.datetime.now() < _token_expires_at - dt.timedelta(minutes=5):
            return _access_token
    
    # Request new token
    url = "https://api.box.com/oauth2/token"
    data = {
        "grant_type": "client_credentials",
        "client_id": BOX_CLIENT_ID,
        "client_secret": BOX_CLIENT_SECRET,
        "box_subject_type": "user",
        "box_subject_id": "13817020641"  # Your Box User ID
    }
    
    r = requests.post(url, data=data, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"Failed to get access token: {r.status_code} - {r.text[:400]}")
    
    token_data = r.json()
    _access_token = token_data["access_token"]
    expires_in = token_data.get("expires_in", 3600)
    _token_expires_at = dt.datetime.now() + dt.timedelta(seconds=expires_in)
    
    return _access_token

def box_headers():
    token = get_access_token()
    return {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }

def box_get_json(url: str) -> dict:
    r = requests.get(url, headers=box_headers(), timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"Box API error {r.status_code}: {r.text[:400]}")
    return r.json()

def box_list_folder(folder_id: str) -> list:
    """List items in a Box folder"""
    url = f"https://api.box.com/2.0/folders/{folder_id}/items?limit=1000"
    data = box_get_json(url)
    return data.get("entries", [])

def parse_ddmmyyyy(s: str) -> dt.date:
    return dt.datetime.strptime(s, "%d-%m-%Y").date()

def find_latest_date_folder(folder_id: str):
    """Find the latest dd-mm-yyyy subfolder in the given Box folder"""
    items = box_list_folder(folder_id)
    candidates = []
    for it in items:
        if it.get("type") == "folder":
            name = it.get("name", "")
            if DATE_RE.match(name):
                try:
                    candidates.append((parse_ddmmyyyy(name), name, it.get("id")))
                except Exception:
                    pass
    if not candidates:
        raise RuntimeError(f"No dd-mm-yyyy folders found in Box folder ID: {folder_id}")
    candidates.sort(key=lambda x: x[0])
    latest_date, latest_name, latest_id = candidates[-1]
    return latest_id, latest_name, latest_date

def walk_files(folder_id: str, path_prefix: str = ""):
    """Recursively walk all files in a Box folder"""
    items = box_list_folder(folder_id)
    for it in items:
        t = it.get("type")
        name = it.get("name", "")
        item_path = f"{path_prefix}/{name}" if path_prefix else name
        if t == "file":
            yield {
                "id": it.get("id"),
                "name": name,
                "path": item_path,
                "size": it.get("size", 0)
            }
        elif t == "folder":
            yield from walk_files(it.get("id"), item_path)

def is_relevant(name: str) -> bool:
    n = (name or "").lower()
    if READ_EXTS and not n.endswith(READ_EXTS):
        return False
    if KEYWORDS and not any(k in n for k in KEYWORDS):
        return False
    return True

def download_file(file_id: str) -> bytes:
    """Download file content from Box"""
    url = f"https://api.box.com/2.0/files/{file_id}/content"
    r = requests.get(url, headers=box_headers(), stream=True, timeout=180, allow_redirects=True)
    if r.status_code != 200:
        raise RuntimeError(f"Download failed {r.status_code}: {file_id}")
    buf = bytearray()
    for chunk in r.iter_content(chunk_size=65536):
        if not chunk:
            continue
        buf.extend(chunk)
        if len(buf) > MAX_BYTES_PER_FILE:
            raise RuntimeError(f"EXCEEDS_MAX_BYTES ({len(buf)} > {MAX_BYTES_PER_FILE})")
    return bytes(buf)

# =========================
# PARSERS
# =========================
def decode_text(data: bytes) -> str:
    for enc in ("utf-8", "utf-16", "cp1252", "latin-1"):
        try:
            return data.decode(enc)
        except Exception:
            continue
    return data.decode("latin-1", errors="replace")

def extract_pdf_text(data: bytes) -> str:
    if pdfplumber is not None:
        parts = []
        with pdfplumber.open(io.BytesIO(data)) as pdf:
            for page in pdf.pages:
                txt = page.extract_text() or ""
                if txt.strip():
                    parts.append(txt)
        return "\n".join(parts).strip()
    if PdfReader is not None:
        reader = PdfReader(io.BytesIO(data))
        parts = []
        for p in reader.pages:
            txt = p.extract_text() or ""
            if txt.strip():
                parts.append(txt)
        return "\n".join(parts).strip()
    return "[PARSE_ERROR] Install pdfplumber or pypdf to extract PDF text."

def extract_excel_text(data: bytes) -> str:
    if pd is None:
        return "[PARSE_ERROR] Install pandas+openpyxl to read Excel."
    xls = pd.ExcelFile(io.BytesIO(data))
    out = []
    for sheet in xls.sheet_names:
        df = pd.read_excel(xls, sheet_name=sheet)
        out.append(f"--- SHEET: {sheet} ---")
        out.append(df.to_csv(index=False))
    return "\n".join(out).strip()

def extract_csv_text(data: bytes) -> str:
    if pd is None:
        return decode_text(data)
    df = pd.read_csv(io.BytesIO(data))
    return df.to_csv(index=False)

def cap_text(text: str) -> tuple:
    if len(text) > MAX_CHARS_PER_FILE:
        return text[:MAX_CHARS_PER_FILE], True
    return text, False

# =========================
# MAIN (CONTEXT BLOCK OUTPUT)
# =========================
def main():
    print("TASK: Read Daily Analysis Report files (Excel/CSV/PDF) from Box.")
    print("AUTH: Using OAuth 2.0 Client Credentials Grant (permanent)")
    print(f"BOX_FOLDER_ID: {BOX_FOLDER_ID}")
    print(f"READ_EXTS: {', '.join(READ_EXTS) if READ_EXTS else '(none)'}")
    print(f"READ_KEYWORDS: {', '.join(KEYWORDS) if KEYWORDS else '(none)'}")
    print(f"PER_FILE_CAP: ~{TOKENS_PER_FILE} tokens (~{MAX_CHARS_PER_FILE} chars)")
    print()

    latest_id, latest_name, latest_date = find_latest_date_folder(BOX_FOLDER_ID)
    
    # Enumerate ALL files in the latest date folder
    all_files = list(walk_files(latest_id, latest_name))
    relevant = [f for f in all_files if is_relevant(f.get("name", ""))]

    print("CONTEXT_BLOCK_START")
    print(f"TARGET_DATE: {latest_date.strftime('%d-%m-%Y')}")
    print(f"LATEST_FOLDER: {latest_name}")
    print(f"FILES_FOUND_TOTAL: {len(all_files)}")
    print(f"FILES_RELEVANT: {len(relevant)}")
    print()

    for it in relevant:
        file_id = it.get("id", "")
        path = it.get("path", "")
        name = it.get("name", "")
        size = it.get("size", 0)

        print("=== START OF FILE ===")
        print(f"PATH: {path}")
        print(f"NAME: {name}")
        print(f"SIZE_BYTES: {size}")

        if not file_id:
            print("STATUS: ERROR (missing file_id)")
            print("=== END OF FILE ===\n")
            continue

        try:
            b = download_file(file_id)
            n = name.lower()
            if n.endswith(".pdf"):
                text = extract_pdf_text(b)
            elif n.endswith(".csv"):
                text = extract_csv_text(b)
            elif n.endswith(".xlsx") or n.endswith(".xls"):
                text = extract_excel_text(b)
            else:
                text = decode_text(b)

            text, truncated = cap_text(text)
            print(f"TRUNCATED: {str(truncated).lower()} (cap ~{TOKENS_PER_FILE} tokens)")
            print("--- CONTENT ---")
            print(text)
        except Exception as e:
            print(f"STATUS: ERROR ({e})")

        print("=== END OF FILE ===\n")

    print("CONTEXT_BLOCK_END")

if __name__ == "__main__":
    main()
